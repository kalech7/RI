{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de Datos stemming eliminacion de stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en 'review_content': 65806\n"
     ]
    }
   ],
   "source": [
    "# Descargar el conjunto de stopwords de nltk si no lo tienes\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Inicializar el Stemmer y las stopwords\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Función de preprocesamiento de texto\n",
    "def preprocess_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar caracteres especiales y números\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    # Tokenizar, eliminar stopwords y aplicar stemming\n",
    "    tokens = [stemmer.stem(word) for word in text.split() if word not in stop_words]\n",
    "    # Unir los tokens procesados\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Cargar los datos\n",
    "movies_path = \"data/rotten_tomatoes_movies.csv\"\n",
    "reviews_path = \"data/rotten_tomatoes_critic_reviews.csv\"\n",
    "\n",
    "movies_df = pd.read_csv(movies_path)\n",
    "reviews_df = pd.read_csv(reviews_path)\n",
    "\n",
    "# Preprocesar la columna de críticas\n",
    "print(\"Valores nulos en 'review_content':\", reviews_df['review_content'].isnull().sum())\n",
    "reviews_df = reviews_df[reviews_df['review_content'].notnull()]\n",
    "reviews_df['processed_review'] = reviews_df['review_content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         movie_title  \\\n",
      "0  Percy Jackson & the Olympians: The Lightning T...   \n",
      "1  Percy Jackson & the Olympians: The Lightning T...   \n",
      "2  Percy Jackson & the Olympians: The Lightning T...   \n",
      "3  Percy Jackson & the Olympians: The Lightning T...   \n",
      "4  Percy Jackson & the Olympians: The Lightning T...   \n",
      "\n",
      "                                    processed_review  \n",
      "0  fantasi adventur fuse greek mytholog contempor...  \n",
      "1  uma thurman medusa gorgon coiffur writh snake ...  \n",
      "2  topnotch cast dazzl special effect tide teen n...  \n",
      "3  whether audienc get behind lightn thief hard p...  \n",
      "4  what realli lack lightn thief genuin sens wond...  \n"
     ]
    }
   ],
   "source": [
    "# Crear la matriz TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(reviews_df['processed_review'])\n",
    "\n",
    "# Vincular críticas con títulos de películas\n",
    "reviews_with_titles = reviews_df.merge(movies_df[['rotten_tomatoes_link', 'movie_title']], \n",
    "                                       on='rotten_tomatoes_link', how='left')\n",
    "\n",
    "# Mostrar las primeras filas para confirmar\n",
    "print(reviews_with_titles[['movie_title', 'processed_review']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor de busqueda "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distancia Jaccard y tratamiento de la query (stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     movie_title            processed_review  \\\n",
      "593655               Out of Time             shrewd thriller   \n",
      "417573  In the Heat of the Night             superb thriller   \n",
      "725100             Secret Window  solidbutimperfect thriller   \n",
      "28065                Dream Lover            satisfi thriller   \n",
      "25052                    Witness             strike thriller   \n",
      "\n",
      "        jaccard_similarity  \n",
      "593655                 0.5  \n",
      "417573                 0.5  \n",
      "725100                 0.5  \n",
      "28065                  0.5  \n",
      "25052                  0.5  \n"
     ]
    }
   ],
   "source": [
    "# Función para calcular la similitud de Jaccard entre dos conjuntos de palabras\n",
    "def jaccard_similarity(query, review):\n",
    "    # Tokenizar las críticas y la consulta en conjuntos de palabras\n",
    "    query_set = set(query.split())\n",
    "    review_set = set(review.split())\n",
    "    \n",
    "    # Calcular la intersección y la unión de los conjuntos\n",
    "    intersection = len(query_set.intersection(review_set))\n",
    "    union = len(query_set.union(review_set))\n",
    "    \n",
    "    return intersection / union\n",
    "\n",
    "# Solicitar la consulta del usuario\n",
    "user_query = input(\"Ingresa tu consulta: \")\n",
    "\n",
    "# Preprocesar la consulta\n",
    "user_query = user_query.lower()\n",
    "\n",
    "# Calcular la similitud de Jaccard para cada crítica\n",
    "reviews_with_titles['jaccard_similarity'] = reviews_with_titles['processed_review'].apply(lambda review: jaccard_similarity(user_query, review))\n",
    "\n",
    "# Ordenar las críticas por similitud de Jaccard, de mayor a menor\n",
    "sorted_reviews = reviews_with_titles.sort_values(by='jaccard_similarity', ascending=False)\n",
    "\n",
    "# Mostrar las primeras 5 críticas más similares\n",
    "print(sorted_reviews[['movie_title', 'processed_review', 'jaccard_similarity']].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
